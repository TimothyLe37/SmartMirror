{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found camera with name: Intel RealSense D455 and serial number: 046122251324\n",
      "{'Intel RealSense D455': '046122251324'}\n"
     ]
    }
   ],
   "source": [
    "def find_cameras(ctx):\n",
    "    devices = ctx.devices\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    for dev in devices:\n",
    "        name = dev.get_info(rs.camera_info.name)\n",
    "        serial_number = dev.get_info(rs.camera_info.serial_number)\n",
    "\n",
    "        data[name] = serial_number\n",
    "        print(\n",
    "            f\"found camera with name: {name} and serial number: {serial_number}\"\n",
    "        )\n",
    "\n",
    "    return data\n",
    "\n",
    "x = rs.context()\n",
    "y = find_cameras(x)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 77\u001b[0m\n\u001b[0;32m     75\u001b[0m points_1 \u001b[38;5;241m=\u001b[39m pc_1\u001b[38;5;241m.\u001b[39mcalculate(aligned_depth_frame_1)\n\u001b[0;32m     76\u001b[0m pc_1\u001b[38;5;241m.\u001b[39mmap_to(aligned_depth_frame_1)\n\u001b[1;32m---> 77\u001b[0m ply_1 \u001b[38;5;241m=\u001b[39m rs\u001b[38;5;241m.\u001b[39msave_to_ply(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mply_file_right/depth\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.ply\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[43mi\u001b[49m))\n\u001b[0;32m     78\u001b[0m ply_1\u001b[38;5;241m.\u001b[39mset_option(rs\u001b[38;5;241m.\u001b[39msave_to_ply\u001b[38;5;241m.\u001b[39moption_ply_binary, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     79\u001b[0m ply_1\u001b[38;5;241m.\u001b[39mset_option(rs\u001b[38;5;241m.\u001b[39msave_to_ply\u001b[38;5;241m.\u001b[39moption_ply_normals, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'i' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Create a context object. This object owns the handles to all connected realsense devices\n",
    "pipeline_1 = rs.pipeline()\n",
    "# pipeline_2 = rs.pipeline()\n",
    "\n",
    "# Configure streams Cam 1\n",
    "config_1 = rs.config()\n",
    "config_1.enable_device('046122251324')\n",
    "config_1.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "config_1.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "\n",
    "# Start streaming Cam 1\n",
    "pipeline_1.start(config_1)\n",
    "pc_1 = rs.pointcloud()\n",
    "\n",
    "# Configure streams Cam 2\n",
    "# config_2 = rs.config()\n",
    "# config_2.enable_device('046322250790')\n",
    "# config_2.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "# config_2.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "\n",
    "# # Start streaming Cam 2\n",
    "# pipeline_2.start(config_2)\n",
    "# pc_2 = rs.pointcloud()\n",
    "# i = 0\n",
    "\n",
    "align_to_1 = rs.stream.color\n",
    "align_1 = rs.align(align_to_1)\n",
    "\n",
    "# align_to_2 = rs.stream.color\n",
    "# align_2 = rs.align(align_to_2)\n",
    "try:\n",
    "    \n",
    "    while True:\n",
    "        # Wait for a coherent pair of frames: depth and color\n",
    "        frames_1 = pipeline_1.wait_for_frames()\n",
    "        # Align the depth frame to color frame\n",
    "        aligned_frames_1 = align_1.process(frames_1)\n",
    "\n",
    "        # Get aligned frames\n",
    "        aligned_depth_frame_1 = aligned_frames_1.get_depth_frame() # aligned_depth_frame is a 640x480 depth image\n",
    "        color_frame_1 = aligned_frames_1.get_color_frame()\n",
    "\n",
    "        # Validate that both frames are valid\n",
    "        if not aligned_depth_frame_1 or not color_frame_1:\n",
    "            continue\n",
    "        \n",
    "        # frames_2 = pipeline_2.wait_for_frames()\n",
    "        # # Align the depth frame to color frame\n",
    "        # aligned_frames_2 = align_2.process(frames_2)\n",
    "\n",
    "        # # Get aligned frames\n",
    "        # aligned_depth_frame_2 = aligned_frames_2.get_depth_frame() # aligned_depth_frame is a 640x480 depth image\n",
    "        # color_frame_2 = aligned_frames_2.get_color_frame()\n",
    "\n",
    "        # Validate that both frames are valid\n",
    "        # if not aligned_depth_frame_2 or not color_frame_2:\n",
    "        #     continue\n",
    "        # Convert images to numpy arrays\n",
    "        depth_image_1 = np.asanyarray(aligned_depth_frame_1.get_data())\n",
    "        color_image_1 = np.asanyarray(color_frame_1.get_data())\n",
    "        # depth_image_2 = np.asanyarray(aligned_depth_frame_2.get_data())\n",
    "        # color_image_2 = np.asanyarray(color_frame_2.get_data())\n",
    "        \n",
    "        images_1 = color_image_1\n",
    "        img_1 = depth_image_1\n",
    "        # images_2 = color_image_2\n",
    "        # img_2 = depth_image_2\n",
    "        # Show images\n",
    "        # cv.namedWindow('RealSense', cv.WINDOW_AUTOSIZE)\n",
    "        cv.imshow('RealSense1', images_1)\n",
    "        # cv.imshow('RealSense2', images_2)\n",
    "        key = cv.waitKey(1)\n",
    "            \n",
    "        #PointCloud\n",
    "        points_1 = pc_1.calculate(aligned_depth_frame_1)\n",
    "        pc_1.map_to(aligned_depth_frame_1)\n",
    "        ply_1 = rs.save_to_ply('ply_file_right/depth{}.ply'.format(i))\n",
    "        ply_1.set_option(rs.save_to_ply.option_ply_binary, False)\n",
    "        ply_1.set_option(rs.save_to_ply.option_ply_normals, True)\n",
    "        \n",
    "        # points_2 = pc_2.calculate(aligned_depth_frame_2)\n",
    "        # pc_2.map_to(aligned_depth_frame_2)\n",
    "        # ply_2 = rs.save_to_ply('ply_file_left/depth{}.ply'.format(i))\n",
    "        # ply_2.set_option(rs.save_to_ply.option_ply_binary, False)\n",
    "        # ply_2.set_option(rs.save_to_ply.option_ply_normals, True)\n",
    "                             \n",
    "        # Capture image\n",
    "        if key & 0xFF == ord('c'):\n",
    "            i = i+1\n",
    "            # Capture video\n",
    "            # colorwriter_1.write(color_image_1)\n",
    "            # colorwriter_2.write(color_image_2)\n",
    "            \n",
    "            cv.imwrite('image_right/out{}.png'.format(i), images_1)\n",
    "            cv.imwrite('image_right/img_right/depth{}.png'.format(i), img_1)\n",
    "            ply_1.process(aligned_depth_frame_1)\n",
    "            \n",
    "            # cv.imwrite('image_left/out{}.png'.format(i), images_2)\n",
    "            # cv.imwrite('image_left/img_left/depth{}.png'.format(i), img_2)\n",
    "            # ply_2.process(aligned_depth_frame_2)\n",
    "        # Press esc or 'q' to close the image window\n",
    "        if key & 0xFF == ord('q') or key == 27:\n",
    "            cv.destroyAllWindows()\n",
    "            break\n",
    "        \n",
    "finally:\n",
    "    # Stop streaming\n",
    "    pipeline_1.stop()\n",
    "    # pipeline_2.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a context object. This object owns the handles to all connected realsense devices\n",
    "pipeline_1 = rs.pipeline()\n",
    "pipeline_2 = rs.pipeline()\n",
    "\n",
    "# Configure streams Cam 1\n",
    "config_1 = rs.config()\n",
    "config_1.enable_device('046122251324')\n",
    "config_1.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "config_1.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "\n",
    "color_path_1 = 'V00P00A00C00_rgb_1.avi'\n",
    "colorwriter_1 = cv.VideoWriter(color_path_1, cv.VideoWriter_fourcc(*'XVID'), 30, (640,480), 1)\n",
    "# Start streaming Cam 1\n",
    "pipeline_1.start(config_1)\n",
    "\n",
    "# Configure streams Cam 2\n",
    "config_2 = rs.config()\n",
    "config_2.enable_device('046322250790')\n",
    "config_2.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "config_2.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "\n",
    "color_path_2 = 'V00P00A00C00_rgb_2.avi'\n",
    "colorwriter_2 = cv.VideoWriter(color_path_2, cv.VideoWriter_fourcc(*'XVID'), 30, (640,480), 1)\n",
    "# Start streaming Cam 2\n",
    "pipeline_2.start(config_2)\n",
    "\n",
    "align_to_1 = rs.stream.color\n",
    "align_1 = rs.align(align_to_1)\n",
    "\n",
    "align_to_2 = rs.stream.color\n",
    "align_2 = rs.align(align_to_2)\n",
    "try:\n",
    "    \n",
    "    while True:\n",
    "        # Wait for a coherent pair of frames: depth and color\n",
    "        frames_1 = pipeline_1.wait_for_frames()\n",
    "        # Align the depth frame to color frame\n",
    "        aligned_frames_1 = align_1.process(frames_1)\n",
    "\n",
    "        # Get aligned frames\n",
    "        aligned_depth_frame_1 = aligned_frames_1.get_depth_frame() # aligned_depth_frame is a 640x480 depth image\n",
    "        color_frame_1 = aligned_frames_1.get_color_frame()\n",
    "\n",
    "        # Validate that both frames are valid\n",
    "        if not aligned_depth_frame_1 or not color_frame_1:\n",
    "            continue\n",
    "        \n",
    "        frames_2 = pipeline_2.wait_for_frames()\n",
    "        # Align the depth frame to color frame\n",
    "        aligned_frames_2 = align_2.process(frames_2)\n",
    "\n",
    "        # Get aligned frames\n",
    "        aligned_depth_frame_2 = aligned_frames_2.get_depth_frame() # aligned_depth_frame is a 640x480 depth image\n",
    "        color_frame_2 = aligned_frames_2.get_color_frame()\n",
    "\n",
    "        # Validate that both frames are valid\n",
    "        if not aligned_depth_frame_2 or not color_frame_2:\n",
    "            continue\n",
    "        # Convert images to numpy arrays\n",
    "        depth_image_1 = np.asanyarray(aligned_depth_frame_1.get_data())\n",
    "        color_image_1 = np.asanyarray(color_frame_1.get_data())\n",
    "        depth_image_2 = np.asanyarray(aligned_depth_frame_2.get_data())\n",
    "        color_image_2 = np.asanyarray(color_frame_2.get_data())\n",
    "        \n",
    "        images_1 = color_image_1\n",
    "        img_1 = depth_image_1\n",
    "        images_2 = color_image_2\n",
    "        img_2 = depth_image_2\n",
    "        # Show images\n",
    "        # cv.namedWindow('RealSense', cv.WINDOW_AUTOSIZE)\n",
    "        cv.imshow('RealSense1', images_1)\n",
    "        cv.imshow('RealSense2', images_2)\n",
    "        key = cv.waitKey(1)\n",
    "        # Capture video\n",
    "        colorwriter_1.write(color_image_1)\n",
    "        colorwriter_2.write(color_image_2)\n",
    "        # Press esc or 'q' to close the image window\n",
    "        if key & 0xFF == ord('q') or key == 27:\n",
    "            cv.destroyAllWindows()\n",
    "            break\n",
    "        \n",
    "finally:\n",
    "    # Stop streaming\n",
    "    pipeline_1.stop()\n",
    "    pipeline_2.stop()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3567e1a2fc4c5c9ec5dddff0ee851051e0db24e0e7dd34ff4fb0bd705b86c93d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('lulem')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
